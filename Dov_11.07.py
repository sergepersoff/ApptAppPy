#WORKING CODE 12/14/23


import os
import re
import pandas as pd
import numpy as np
from fuzzywuzzy import fuzz
from datetime import timedelta 
import chardet
from unidecode import unidecode
import pandas as pd
from pathlib import Path
import sqlite3
import pickle

# Read the CSV file
file_path = r'C:\Users\serge\Desktop\DOV\Master_Schedule_October.csv'
df = pd.read_csv(file_path, encoding='ISO-8859-1')

# Remove the quotation marks from the 'Practitioner' column
df['Practitioner'] = df['Practitioner'].str.replace('"', '')

# Save the cleaned DataFrame back to the same CSV file
df.to_csv(file_path, index=False, encoding='ISO-8859-1')

# Load the file with the appropriate encoding
file_path = r'C:\Users\serge\Desktop\DOV\Master_Schedule_October.csv'
df = pd.read_csv(file_path, encoding='ISO-8859-1')

# Convert everything to upper case
df = df.applymap(lambda x: x.upper() if isinstance(x, str) else x)

# Reformat 'Practitioner' to 'last name, first name'
def reformat_name(name):
    if not isinstance(name, str):  # Check if the value is not a string
        return name  # Return the original value (could be NaN or something else)
        
    parts = name.split()
    if len(parts) >= 2:
        return f"{parts[-1]}, {' '.join(parts[:-1])}"
    return name

df['Practitioner'] = df['Practitioner'].apply(reformat_name)

# Filter based on the given criteria
df = df[df['Facility'].notna()]  # Filter out all nulls in the 'Facility' column
df = df[df['Specialty'] != 'RETINAL ASSMT.']  # Exclude 'RETINAL ASSMT.' in the 'Specialty' column
df = df[df['Total Provider Cost'] != 0]  # Exclude rows where 'Total Provider Cost' is 0
df = df[df['PT Encounter'] != 0]  # Exclude rows where 'PT Encounter' is 0
df = df[df['Facility'] != 'ROSARY HILL HOME']

# Save the filtered data to a new file
output_path = r'C:\Users\serge\Documents\My Tableau Prep Repository\Datasources\Master.csv'
df.to_csv(output_path, index=False)

print(f"Data has been saved to {output_path}")

# Load the Master.csv
master_path = r'C:\Users\serge\Documents\My Tableau Prep Repository\Datasources\Master.csv'
df_master = pd.read_csv(master_path, encoding='ISO-8859-1')

replacement_dict_master = {
    'ST. JOHNLAND NURSING CENTER': 'ST. JOHNLAND NURSING CENTER',
    'VECS ST. JOHNLAND NURSING CENTER': 'ST. JOHNLAND NURSING CENTER',
    'MCGUIRE GROUP - NORTHGATE HEALTH CARE FACILITY (COPY)': 'NORTHGATE',
    'MCGUIRE GROUP - NORTHGATE HEALTH CARE FACILITY': 'NORTHGATE',
    'MAPLE CITY REHAB AND NURSING (FORMERLY HORNELL GARDENS)': 'MAPLE LEAF HEALTHCARE CENTER',
    'BREEZY HILLS': 'BREEZY HILLS REHAB AND CARE CENTER',
    'NORWEGIAN CHRISTIAN HOME & HEALTH CENTER': 'NORWEGIAN CHRISTIAN HOME AND HEALTH CENTER',
    'HIGHBRIDGE WOODYCREST': 'HIGHBRIDGE WOODYCREST CENTER',
    'VECS ALF THE BRIELLE AT SEAVIEW': 'SEA VIEW HOSPITAL REHABILITATION CENTER AND HOME',
    'ELM MANOR NURSING AND REHABILITATION CENTER (COPY)': 'ELM MANOR NURSING AND REHABILITATION CENTER',
    'VECS FERRY ASSISTED LIVING': 'VECS VINCENT BOVE HEALTH CENTER AT JEFFERSON FERRY',
    'WATERFRONT (FORMERLY REHAB AT RIVER\'S EDGE)': 'REHAB AT RIVER\'S EDGE'
}

df_master['Facility'] = df_master['Facility'].replace(replacement_dict_master)


# Save the changes back to the same CSV file
df_master.to_csv(master_path, index=False, encoding='ISO-8859-1')

# Read the CSV and suppress the DtypeWarning
df = pd.read_csv(r'C:\Users\serge\Desktop\DOV\2023\HHA_Dov_2023.csv', low_memory=False)

# Filter the dataframe based on given practice codes
filter_practices = ['EVO', 'FFP', 'IPA', 'MFL', 'OFF', 'RDP', 'ICF']
df_filtered = df[df['Practice Code'].isin(filter_practices)].copy()  # Added .copy() to avoid the SettingWithCopyWarning

# Format 'Date of Service' as date
df_filtered.loc[:, 'Date of Service'] = pd.to_datetime(df_filtered['Date of Service'])

# Rename the 'Transaction Code (Charge, Payment or Adjustment)' column to 'Transaction Code'
df_filtered.rename(columns={'Transaction Code (Charge, Payment or Adjustment)': 'Transaction Code'}, inplace=True)

# Convert 'Transaction Code' column to string type
df_filtered['Transaction Code'] = df_filtered['Transaction Code'].astype(str)

# Trim extra spaces from 'Location of Service Name'
df_filtered.loc[:, 'Location of Service Name'] = df_filtered['Location of Service Name'].str.strip()

# Save the cleaned data
output_path = r'C:\Users\serge\Documents\My Tableau Prep Repository\Datasources\2023.csv'
df_filtered.to_csv(output_path, index=False)

print("File has been saved successfully!")

# Load the 2023.csv
path_2023 = r'C:\Users\serge\Documents\My Tableau Prep Repository\Datasources\2023.csv'
df_2023 = pd.read_csv(path_2023, encoding='ISO-8859-1')


replacement_dict_2023 = {
    'ST. JOHNLAND NURSING CENTER': 'ST. JOHNLAND NURSING CENTER',
    'ST. JOHNLAND ASSISTED LIVING, INC': 'ST. JOHNLAND ASSISTED LIVING, INC.',
    'ST.JOHNLAND NURSING CENTER': 'ST. JOHNLAND NURSING CENTER',
    'MERRIMACK COUNTY ALF (GERRISH)': 'MERRIMACK COUNTY ASSISTED LIVING (GERRISH MANOR)',
    'MAPLE CITY REHAB AND NURSING (FORMERLY HORNELL GARDENS)': 'MAPLE LEAF HEALTHCARE CENTER'
}

df_2023['Location of Service Name'] = df_2023['Location of Service Name'].replace(replacement_dict_2023)


df_2023['Location of Service Name'] = df_2023['Location of Service Name'].replace('MAPLE CITY REHAB AND NURSING (FORMERLY HORNELL GARDENS)', 'MAPLE LEAF HEALTHCARE CENTER')


# Save the changes back to the same CSV file
df_2023.to_csv(path_2023, index=False, encoding='ISO-8859-1')

# Function to check if two dates are within a specified time window (e.g., 7 days)
def within_time_window(date1, date2, time_window):
    return abs((date1 - date2).days) <= time_window

# Specify the time window for matching "Date of Service" (e.g., 7 days)
time_window_days = 7

# Read the "2023" file
df_2023 = pd.read_csv(r"C:\Users\serge\Documents\My Tableau Prep Repository\Datasources\2023.csv", encoding="utf-8-sig")

# Read the "Master" file with the list of problematic locations
df_master = pd.read_csv(r"C:\Users\serge\Documents\My Tableau Prep Repository\Datasources\Master.csv", encoding="utf-8-sig")

# Replace the specific value in the 'Location of Service Name' column
file_path_master = r'C:\Users\serge\Desktop\DOV\Master_Schedule_1694458736.csv'
master_df = pd.read_csv(file_path_master, encoding='ISO-8859-1')

# Save the changes back to the same CSV file
master_df.to_csv(file_path_master, index=False, encoding='ISO-8859-1')

# Round the "Total Payments Amount" column to 2 decimal places
df_2023["Total Payments Amount"] = df_2023["Total Payments Amount"].round(2)

# Remove leading/trailing whitespaces in the columns for exact matching
df_2023["Provider of Service Name"] = df_2023["Provider of Service Name"].str.strip()
df_2023["Location of Service Name"] = df_2023["Location of Service Name"].str.strip()
df_master["Practitioner"] = df_master["Practitioner"].str.strip()

# Normalize the Facility Name column to NFC form
df_master['Facility'] = df_master['Facility'].str.normalize('NFC')

# Specify the absolute file path of the 'Master.csv' file
file_path = r'C:\Users\serge\Documents\My Tableau Prep Repository\Datasources\Master.csv'

# Read the first few lines of the file to detect the character encoding
with open(file_path, 'rb') as f:
    result = chardet.detect(f.read())

# Get the detected encoding
encoding = result['encoding']

# Read the 'Master.csv' file using the detected encoding
df_master = pd.read_csv(file_path, encoding=encoding)

# Read the 2023.csv file
file_path = r'C:\Users\serge\Documents\My Tableau Prep Repository\Datasources\2023.csv'
df_2023 = pd.read_csv(file_path, encoding='utf-8')

# Function to clean up facility names
def clean_facility_name(name):
    # Remove unwanted characters using regular expression
    cleaned_name = re.sub(r'%\d+', '', name)
    # Clean up the remaining special characters in the facility name using unidecode
    cleaned_name = unidecode(cleaned_name)
    return cleaned_name

# Apply the clean_facility_name function to the "Location of Service Name" column
df_2023['Location of Service Name'] = df_2023['Location of Service Name'].apply(clean_facility_name)

df_2023 = df_2023.replace("_", "", regex=True)

# Print the updated DataFrame to verify the changes
print(df_2023['Location of Service Name'])

# Create a dictionary mapping old location names to new location names
location_changes = {
"ABSOLUTE AT GASPORT, LLC": "ABSOLUT CARE OF GASPORT",
"ABSOLUT AT GASPORT, LLC": "ABSOLUT CARE OF GASPORT",
"BRANDYWINE LIVING AT HUNTINGTON TERRACE": "VECS ALF BRANDYWINE SENIOR LIVING AT HUNTINGTON TERRACE",
"ALF CHELSEA AT GREENBURGH": "VECS ALF THE CHELSEA AT GREENBURGH",
"MYSTIC MEADOWS":"MYSTIC MEADOWS REHAB & NURSING CENTER",
"ABSOLUT AT AURORA PARK,LLC": "ABSOLUT CARE - AURORA PARK",
"ABSOLUT AT ALLEGANY, LLC": "ABSOLUT CARE OF ALLEGANY",
"ABSOLUT AT 3 RIVERS, LLC": "ABSOLUT CARE - THREE RIVERS",
"JOHN E ANDRUS MEMORIAL INC": "ANDRUS ON HUDSON",
"ARABELLA HEALTH & WELLNESS OF CARRABELLE": "ARABELLA HEALTH AND WELLNESS OF CARRABELLE",
"WILLOW GARDENS MEMORY CARE ALF": "VECS ALF WILLOW GARDENS MEMORY CARE",
"ABSOLUT DUNKIRK": "ABSOLUT - DUNKIRK REHABILITATION AND NURSING CENTER",
"ABSOLUT EDEN REHABILITATION": "ABSOLUT - EDEN REHABILITATION AND NURSING CENTER",
"ABSOLUT- HOGHTON REHAB & NURSING CENTER": "ABSOLUT - HOUGHTON REHABILITATION AND NURSING CENTER",
"ACCELA REHAB & CARE CENTER AT SOMERTON": "ACCELA REHAB AND CARE CENTER AT SOMERTON",
"ACCLAIM REHABILITATION & CARE CENTER": "ACCLAIM REHABILITATION AND CARE CENTER",
"AMBASSADOR HEALTHCARE AT COLLEGE PARK": "AMBASSADOR HEALTHCARE AT COLLEGE PARK",
"ANDRUS ON HUDSON - SNF": "ANDRUS ON HUDSON",
"APOLLO HEALTH & REHABILITATION CENTER": "APOLLO HEALTH AND REHABILITATION CENTER",
"BIRCHWOOD PARK REHAB AND NURSING": "BIRCHWOOD PARK REHABILITATION AND NURSING",
"BISHOP REHABILITATION AND NURSING CENTER": "BISHOP REHABILITATION AND NURSING CENTER",
"BRONX CARE SPECIALTY CARE CENTER": "BRONXCARE SPECIAL CARE CENTER",
"BROOKHAVEN CENTER FOR REHAB & HEALTHCARE": "BROOKHAVEN CENTER FOR REHABILITATION AND HEALTHCARE",
"CEDAR GROVE RESPIRATORY AND NURSING CENTER": "CEDAR GROVE RESPIRATORY AND NURSING CENTER",
"CHARLOTTE BAY REHAB & CARE CENTER": "CHARLOTTE BAY REHAB AND CARE CENTER",
"CHAUTAUQUA COUNTY HOME": "CHAUTAUQUA NURSING AND REHABILITATION CENTER",
"COLER REHABILITATION AND NURSING CARE CENTER": "COLER SPECIALTY HOSPITAL AND NURSING FACILITY",
"COLLAR CITY NURSING AND REHAB CENTER": "COLLAR CITY NURSING AND REHABILITATION CENTER",
"COLLAR CITY REHABILITATION": "COLLAR CITY NURSING AND REHABILITATION CENTER",
"COLONIAL PARK REHAB AND NURSING": "COLONIAL PARK REHABILITATION & NURSING CENTER",
"COLONY CENTER FOR HEALTH & REHABILITATION": "COLONY CENTER FOR HEALTH AND REHABILITATION",
"CORAL REEF SUBACUTE CARE CENTER": "CORAL REEF SUBACUTE CARE CENTER",
"CORTLANDT HEALTHACRE": "CORTLANDT HEALTHCARE",
"CYPRESS POINT REHAB AND NURSING": "CYPRESS POINT REHABILITATION AND NURSING",
"DOCTORS SUB ACUTE CARE": "DOCTORS SUB ACUTE CARE",
"ELDERWOOD AT LANCASTER": "ELDERWOOD AT LANCASTER",
"ELDERWOOD AT LIVERPPOL": "ELDERWOOD AT LIVERPOOL",
"ELDERWOOD AT NORTH CREEK": "ELDERWOOD AT NORTH CREEK",
"ELDERWOOD AT WHEATFIELD": "ELDERWOOD AT WHEATFIELD",
"ECHELON CARE AND REHAB CENTER": "ECHELON CARE & REHAB (FORMERLYTHE PINES AT VOORHEES)",
"ELIZABETH NURSING & REHAB CENTER": "ELIZABETH NURSING AND REHAB CENTER",
"ELM MANOR NURSING AND REHAB": "ELM MANOR NURSING AND REHABILITATION CENTER",
"FIDDLERS GREEN MANOR REHAB AND NURSING": "FIDDLERS GREEN MANOR REHABILITATION & NURSING CENTER",
"FINGER LAKES CENTER FOR LIVING": "FINGER LAKES CENTER FOR SENIOR LIVING",
"VINCENT BOVE HEALTH CENETER AT JEFFERSON FERRY": "VECS VINCENT BOVE HEALTH CENTER AT JEFFERSON FERRY",
"FOLTSBROOK CENTER FOR NURSING & REHABILITATION": "FOLTSBROOK CENTER FOR NURSING & REHABILITATION",
"FOLTSBROOK CENTER NURSING AND REHABILITION": "FOLTSBROOK CENTER FOR NURSING & REHABILITATION",
"GHENT REHABILITATION AND NURSING": "GHENT REHABILITATION & SKILLED NURSING CENTER",
"GOLDCREST CARE CENTER INC": "GOLD CREST CARE CENTER",
"GREEN ACRES REHABILITATION & NURSING": "GREEN ACRES REHABILITATION AND NURSING",
"GREEN MOUNTAIN NURSING AND REHABILITATION": "GREEN MOUNTAIN NURSING & REHABILITATION",
"GREENFIELD HEALTH AND REHABILITATION CENTER": "GREENFIELD HEALTH & REHAB CENTER",
"HERITAGE GREEN REHAB & SKILLED NURSING": "HERITAGE GREEN REHAB AND SKILLED NURSING",
"HERITAGE PARK REHAB AND NURSING CENTER": "HERITAGE PARK REHABILITATION AND SKILLED NURSING CENTER",
"HIGHBRIDGE WOODYCREST CENTER": "HIGHBRIDGE WOODYCREST CENTER",
"IRA DAVENPORT SKILLED NURSING FACILITY": "IRA DAVENPORT MEMORIAL HOSPITAL SNF/HRF",
"HIGHLAND NURSING HOME": "HIGHLAND REHAB",
"HIGHPOINTE ON MICHIGAN": "HIGHPOINTE ON MICHIGAN",
"HORIZON CARE CENTER": "HORIZON CARE CENTER",
"HUMBOLDT HOUSE REHAB & NURSING CTR": "HUMBOLDT HOUSE REHABILITATION & NURSING CENTER",
"HUMBOLDT HOUSE REHABILITATION & NURSING CENTER": "HUMBOLDT HOUSE REHABILITATION & NURSING CENTER",
"GLEN ARDEN HEALTH CARE CENTER": "VECS GLEN ARDEN HEALTH CARE CENTER",
"HUNTINGTON LIVING CENTER": "HUNTINGTON LIVING CENTER",
"JEWISH HOME FOR REHAB & NURSING": "JEWISH HOME FOR REHABILITATION & NURSING",
"KENDAL AT ITHACA": "KENDAL AT ITHACA",
"KIRKHAVEN (GENESEE VALLEY PRESBYTERIAN NURSING CENTER)": "KIRKHAVEN (GENESEE VALLEY PRESBYTERIAN NURSING CENTER)",
"LAUREL MANOR HEALTHCARE AND REHAB": "LAUREL MANOR HEALTHCARE AND REHABILITATION CENTER",
"LEXINGTON HEALTH & REHABILITATION": "LEXINGTON HEALTH AND REHABILITATION CENTER", 
"LIVINGSTON HILLS NURSING HOME": "LIVINGSTON HILLS NURSING & REHABILITATION CENTER",
"MARYVILLE ENHANCED ASSISTED LIVING": "VECS ALF MARYVILLE ENHANCED ASSISTED LIVING FACILITY",
"MASONIC HOME OF FLORIDA": "MASONIC HOME OF FLORIDA",
"MCGUIRE GROUP - HARRIS HILL": "MCGUIRE GROUP - HARRIS HILL NURSING FACILITY",
"MCGUIRE GROUP - HARRIS HILLS": "MCGUIRE GROUP - HARRIS HILL NURSING FACILITY",
"MCGUIRE GROUP - NORTHGATE": "NORTHGATE",
"WECARE AT WAYNESBURG REHABILITATION AND NURSING CENTERCENTER": "WECARE AT WAYNESBURG",

"MCGUIRE GROUP - SENECA": "MCGUIRE GROUP - SENECA HEALTH CARE CENTER",
"MEDINA MEMORIAL HOSPITAL NURSING HOME": "MEDINA MEMORIAL HOSPITAL NURSING HOME | ORLEANS COMMUNITY HEALTH",
"MIRIAM OSBORN MEMORAIL HOME ASSOCIATION": "MIRIAM OSBORN MEMORIAL HOME ASSOCIATION",
"MONTCLAIR CARE CENTER": "MONTCLAIR CARE CENTER",
"MOUNTAINSIDE": "MOUNTAINSIDE RESIDENTIAL",
"NASSAWADOX REHAB AND NURSING": "NASSAWADOX REHABILITATION AND NURSING",
"NIAGARA FALLS MEMORIAL MEDICAL CENTER - SCHOELLKOPF HEALTH": "NIAGARA FALLS MEMORIAL MEDICAL CENTER - SCHOELLKOPF HEALTH CENTER",
"NIAGRA REHAB AND NURSING": "NIAGARA REHABILITATION & NURSING CENTER",
"NORTHERN CARDINAL REHABILITATION & NURSING": "NORTHERN CARDINAL REHABILITATION AND NURSING",
"NORTHERN CARDINAL REHAB AND NURSING": "NORTHERN CARDINAL REHABILITATION AND NURSING",
"NORVIEW HEIGHTS REHAB AND NURSING": "NORVIEW HEIGHTS REHABILITATION AND NURSING",
"NORVIEW HEIGHTS REHABILITATION & NURSING": "NORVIEW HEIGHTS REHABILITATION AND NURSING",
"NORWEGIAN CHRISTIAN HOME & HEALTH CENTER": "NORWEGIAN CHRISTIAN HOME AND HEALTH CENTER",
"NORWEGIAN CHRISTIAN HOME AND HEALTH": "NORWEGIAN CHRISTIAN HOME AND HEALTH CENTER",
"OLD DOMINION REHAB AND NURSING": "OLD DOMINION REHABILITATION AND NURSING",
"OLD DOMINION REHABILITATION & NURSING": "OLD DOMINION REHABILITATION AND NURSING",
"OUR LADYS CENTER FOR REHABILITATION AND HEALTHCARE": "OUR LADY'S CENTER FOR REHABILITATION AND HEALTHCARE",
"PEARL NURSING CENTER OF ROCHESTER": "PEARL NURSING CENTER (FORMERLY NEWROC NURSING HOME)",
"THE PEARL NURSING CENTER": "PEARL NURSING CENTER (FORMERLY NEWROC NURSING HOME)",
"PORT CHARLOTTE CENTER FOR NURSING AND REHAB": "PORT CHARLOTTE CENTER FOR NURSING AND REHABILITATION",
"REHAB AT RIVERS EDGE": "REHAB AT RIVER'S EDGE",
"RIVERS EDGE REHABILITATION AHD HEALTHCARE CENTER":"RIVER'S EDGE REHABILITATION AND HEALTHCARE CENTER",
"RENAISSANCE REHAB AND NURSING CARE CENTER": "RENAISSANCE REHABILITATION AND NURSING CARE CENTER",
"RENAISSANCE REHABILITATION AND NURSING CARE CENTER":"RENAISSANCE AT LINCOLN PARK",
"SCHEDECTADY COUNTY GLENDALE HOME": "SCHENECTADY COUNTY GLENDALE HOME",
"SCHUYLKILL CENTER":"SCHUYKILL CENTER",
"THE EMERALD PEEK REHABILITATION AND NURSING CENTER":"THE EMERALD PEEK REHABILITATION & NURSING CENTER",
"SEA VIEW REHAB CENTER":"THE BRIELLE AT SEAVIEW",
"BEACH BREEZE":"BEACH BREEZE REHAB AND CARE",
"BREEZY HILLS":"BREEZY HILLS REHAB AND CARE CENTER",
"SEA VIEW HOSPITAL REHAB CENTER": "SEA VIEW HOSPITAL REHABILITATION CENTER AND HOME",
"SEA VIEW REHAB CENTER": "SEA VIEW HOSPITAL REHABILITATION CENTER AND HOME",
"SINAI POS-ACUTE NURSING AND REHAB": "SINAI POST-ACUTE NURSING & REHAB CENTER",
"SINAI POST-ACUTE NURSING & REHAB CENTER": "SINAI POST-ACUTE NURSING & REHAB CENTER",
"SPLIT ROCK REHAB AND HEALTHCARE CENTER": "SPLIT ROCK REHABILITATION AND HEALTH CARE CENTER",
"SPRING CREEK REHAB AND NURSING": "SPRING CREEK REHABILITATION AND NURSING CENTER",
"SPRING CREEK REHAB AND NURSING CENTER": "SPRING CREEK REHABILITATION AND NURSING CENTER",
"ST ANNS HOME FOR THE AGED": "ST. ANN'S HOME FOR THE AGED (PORTLAND AVE.)",
"ST ANNS NURSING HOME": "ST. ANN'S NURSING HOME, INC. (CHERRY RIDGE)",
"ST CATHERINE LABOURE HEALTH CARE CENTER": "ST. CATHERINE LABOURE HEALTH CARE CENTER",
"ST.CATHERINE OF SIENA NURSING HOME": "ST. CATHERINE LABOURE HEALTH CARE CENTER",
"TACONIC REHAB AT BEACON": "TACONIC REHABILITATION AND NURSING AT BEACON",
"TACONIC REHAB AND NURSING AT BEACON": "TACONIC REHABILITATION AND NURSING AT BEACON",
"TACONIC REHABILITATION & NURSING AT HOPEWELL": "TACONIC REHABILITATION AND NURSING AT HOPEWELL",
"TACONIC REHAB AND NURSING AT HOPEWELL": "TACONIC REHABILITATION AND NURSING AT HOPEWELL",
"TACONIC REHAB AT ULSTER": "TACONIC REHABILITATION AND NURSING AT ULSTER",
"TACONIC REHAB AND NURSING AT ULSTER": "TACONIC REHABILITATION AND NURSING AT ULSTER",
"TERESIAN HOUSE NURSING HOME COMPANY INC.": "TERESIAN HOUSE",
"TERRACE VIEW LONG TERM CARE": "TERRACE VIEW LONG TERM CARE",
"TERRACE VIEW LTC": "TERRACE VIEW LONG TERM CARE",
"THALIA GARDENS REHAB ABD NURSING": "THALIA GARDENS REHABILITATION AND NURSING",
"THE BROOK AT HIGH FALLS NURSING AND REHAB CENTER": "THE BROOK AT HIGH FALLS NURSING & REHABILITATION CENTER",
"THE CENTERS AT ST CAMILUS": "THE CENTERS AT ST. CAMILLUS",
"THE ELEANOR NURSING CARE CENTER": "THE ELEANOR NURSING CARE CENTER",
"THE GRAND AT ROME": "THE GRAND REHABILITATION & NURSING AT ROME",
"THE GRAND REHAB AT UTICA": "THE GRAND REHABILITATION & NURSING AT UTICA",
"THE GRAND REHABILITATION AND NURSING AT BATAVIA - SNF": "THE GRAND REHABILITATION AND NURSING AT BATAVIA",
"THE HOMESTEAD AT SOLDIERS AND SAILORS MEMORIAL HOSPITAL": "THE HOMESTEAD AT SOLDIERS & SAILORS MEMORIAL HOSPITAL",
"THE VILLAGES OF ORLEANS HEALTH & REBAB CENTER": "THE VILLAGES OF ORLEANS HEALTH AND REHABILITATION CENTER",
"ALF SUNRISE OF WEST BABYLON": "VECS ALF SUNRISE OF WEST BABYLON",
"WESLEY GARDENS": "WESLEY GARDENS",
"WESLEY GARDENS CORP": "WESLEY GARDENS",
"WEST ORANGE CENTER FOR NURSING AND HEALING": "WEST ORANGE CENTER FOR NURSING AND HEALING",
"WILLIAMSBRIDGE CENTER FOR REHABILITATION & NURSING": "WILLIAMSBRIDGE CENTER FOR REHABILITATION AND NURSING",
"SHAKER PLACE ALBANY COUNTY": "SHAKER PLACE REHABILITATION AND NURSING CENTER (ALBANY COUNTY)",
"SUSAN SMITH MCKINNEY REHABILITATION CENTER & NURSING HOME": "SUSAN SMITH MCKINNEY REHABILITATION CENTER AND NURSING HOME",
"SUSQUEHANNA NURSING & REHABILITATION CENTER": "SUSQUEHANNA NURSING AND REHABILITATION CENTER",
"SWAN LAKE NURSING AND REHAB": "SWAN LAKE NURSING AND REHABILITATION",
"THE ABSOLUT AT WESTFIELD, LLC": "ABSOLUT CARE OF WESTFIELD",
"DABSOLUT AT WESTFIELD, LLC": "ABSOLUT CARE OF WESTFIELD",
"ABSOLUTE CENTER FOR NURSING & REHAB AT WESTFIELD": "ABSOLUT CARE OF WESTFIELD",
"JAMAICA HOSPITAL NURSING HOME": "VECS JAMAICA HOSPITAL NURSING HOME",
"MARIA REGINA RESIDENCE": "VECS MARIA REGINA RESIDENCE",
"BROOKHAVEN HEALTH CARE FACILITY": "VECS MCGUIRE GROUP-BROOKHAVEN HEALTH CARE FACILITY",
"BRAEMAR AT MEDFORD ALF": "VECS ALF BRAEMAR AT MEDFORD",
"BRISTAL ASSISTED LIVING AT EAST NORTHPORT": "VECS ALF BRISTAL ASSISTED LIVING AT MASSAPEQUA",
"THE BRISTAL AT MASSAPEQUA": "VECS ALF BRISTAL ASSISTED LIVING AT MASSAPEQUA",
"NYS VETERANS HOME AT ST.ALBANS": "VECS NEW YORK STATE VETERANS HOME, ST. ALBANS",
"305 WEST END ASSISTED LIVING": "VECS ALF 305 WEST END ASSISTED LIVING",
"ARTIS SENIOR LIVING OF SOMERS": "VECS ALF ARTIS SENIOR LIVING OF SOMERS",
"ATRIA GREAT NECK ALF": "VECS ALF ATRIA PARK OF GREAT NECK",
"BELVEDERE SENIOR LIVING": "VECS ALF BELVEDERE SENIOR LIVING",
"QUEENS BOULEVARD ALP": "VECS ALF BOULEVARD ALP QUEENS",
"ELMORE ADULT HOME ALF": "VECS ALF ELMORE ADULT HOME",
"SAN SIMEON BY SOUND CENTER FOR NURSING AND REHABILITATION": "VECS SAN SIMEON BY THE SOUND CENTER FOR NURSING AND REHABILITATION",
"NEW HOMESTEAD HOME FOR ADULTS": "VECS ALF NEW HOMESTEAD HOME FOR ADULTS",
"NORTHERN RIVERVIEW": "VECS ALF NORTHERN RIVERVIEW ASSISTED LIVING",
"CASTLE SENIOR LIVING AT FOREST HILLS": "VECS ALF CASTLE SENIOR LIVING AT FOREST HILLS",
"PROMENADE AT CHESTNUT RIDGE ASSISTED LIVING": "VECS ALF PROMENADE AT CHESTNUT RIDGE",
"PROMENADE AT TUXEDO": "VECS ALF PROMENADE AT TUXEDO PLACE",
"SOMERSET GARDENS BY CHELSEA": "VECS ALF SOMERSET GARDENS SENIOR LIVING",
"ARBORS AT WESTBURY ASSISTED LIVING": "VECS ALF THE ARBORS AT WESTBURY",
"THE KENSINGTON WHITE PLAINS": "VECS ALF THE KENSINGTON WHITE PLAINS",
"THE BRISTAL ASSISTED LIVING AT JERICHO": "VECS ALF BRISTAL ASSISTED LIVING AT JERICHO",
"THE BRISTAL AT EAST MEADOW": "VECS ALF BRISTAL ASSISTED LIVING AT EAST MEADOW",
"THE BRISTAL AT LAKE GROVE ALF": "VECS ALF BRISTAL ASSISTED LIVING AT LAKE GROVE",
"THE BRISTAL AT NORTH HILLS": "VECS ALF BRISTAL ASSISTED LIVING AT NORTH HILLS",
"THE BRISTAL AT SAYVILLE": "VECS ALF BRISTAL ASSISTED LIVING AT SAYVILLE",
"THE BRISTAL AT YORK AVENUE ALF": "VECS ALF BRISTAL ASSISTED LIVING AT YORK AVENUE",
"THE BRISTAL AT WESTBURY": "VECS ALF BRISTAL ASSISTED LIVING AT WESTBURY",

"AMSTERDAM AT HARBORSIDE": "VECS AMSTERDAM AT HARBORSIDE (AMSTERDAM HOUSE CONTINUING CARE RETIREMENT COMMUNITY)",
"GOOD SAMARITAN HOSPITAL MEDICAL CENTER": "VECS GOOD SAMARITAN HOSPITAL MEDICAL CENTER NURSING HOME",
"GURWIN JEWISH NURSING & REHAB CENTER": "VECS GURWIN JEWISH NURSING & REHAB CENTER",
"THE ARBORS AT ISLANDIA EAST ALF": "VECS ALF THE ARBORS AT ISLANDIA EAST",
"VALLEY VIEW CENTER FOR NURSING CARE AND REHABILITATION": "VECS THE VALLEY VIEW CENTER FOR NURSING CARE AND REHABILITATION",
"VILLA CREST NURSING & RETIREMENT CENTER": "VILLA CREST NURSING AND RETIREMENT CENTER",
"NYS VETERANS HOME AT BATAVIA": "VETERANS HOME AT BATAVIA",
"UNIVERSITY CENTER FOR NURSING AND HEALING": "VIVO HEALTHCARE UNIVERSITY CENTER FOR NURSING AND HEALING",
"RFALL RIVER JEWISH HOME": "FALL RIVER JEWISH HOME",
"GENEVA LIVING CENTER NORTH": "LIVING CENTERS AT GENEVA NORTH",
"AUTUMN VIEW": "MCGUIRE GROUP - AUTUMN VIEW HEALTH CARE FACILITY",
"AUTUMN VIEW HEALTH CARE FACILITY": "MCGUIRE GROUP - AUTUMN VIEW HEALTH CARE FACILITY",
"RIVERS EDGE REHAB AND HEALTHCARE CENTER": "RIVER'S EDGE REHABILITATION AND HEALTHCARE CENTER",
"ROSCOE COMMUNITY NURSING HOME CO INC": "ROSCOE NURSING AND REHABILITATION CENTER",
"LEGACY AT BOCA RATON REHABILITATION & NURSING CENTER": "THE LEGACY AT BOCA RATON REHABILITATION AND NURSING CENTER",
"MEADOWS CENTER": "THE MEADOWS CENTER FOR NURSING AND HEALING",
"ATRIA NEW CITY: \"VECS ALF ATRIA NEW CITY\""
"ORCHARD BROOKE ALF": "ABSOLUT CARE OF ORCHARD BROOKE",
"JAMAICA HOSPITAL NURSING HOME": "VECS JAMAICA HOSPITAL NURSING HOME",
"MARIA REGINA RESIDENCE": "VECS MARIA REGINA RESIDENCE",
"BROOKHAVEN HEALTH CARE FACILITY": "VECS MCGUIRE GROUP-BROOKHAVEN HEALTH CARE FACILITY",
"BRISTAL ASSISTED LIVING AT EAST NORTHPORT": "VECS ALF BRISTAL ASSISTED LIVING AT MASSAPEQUA",
"NYS VETERANS HOME AT ST.ALBANS": "VECS NEW YORK STATE VETERANS HOME, ST. ALBANS",
"305 WEST END ASSISTED LIVING": "VECS ALF 305 WEST END ASSISTED LIVING",
"ARTIS SENIOR LIVING OF SOMERS": "VECS ALF ARTIS SENIOR LIVING OF SOMERS",
"CHARMING LAKES": "CHARMING LAKES REHABILITATION & CARE CENTER",
"ATRIA GREAT NECK ALF": "VECS ALF ATRIA PARK OF GREAT NECK",
"BELVEDERE SENIOR LIVING": "VECS ALF BELVEDERE SENIOR LIVING",
"QUEENS BOULEVARD ALP": "VECS ALF BOULEVARD ALP QUEENS",
"ELMORE ADULT HOME ALF": "VECS ALF ELMORE ADULT HOME",
"SAN SIMEON BY SOUND CENTER FOR NURSING AND REHABILITATION": "VECS SAN SIMEON BY THE SOUND CENTER FOR NURSING AND REHABILITATION",
"NEW HOMESTEAD HOME FOR ADULTS": "VECS ALF NEW HOMESTEAD HOME FOR ADULTS",
"NORTHERN RIVERVIEW": "VECS ALF NORTHERN RIVERVIEW ASSISTED LIVING",
"CASTLE SENIOR LIVING AT FOREST HILLS": "VECS ALF CASTLE SENIOR LIVING AT FOREST HILLS",
"PROMENADE AT CHESTNUT RIDGE ASSISTED LIVING": "VECS ALF PROMENADE AT CHESTNUT RIDGE",
"PROMENADE AT TUXEDO": "VECS ALF PROMENADE AT TUXEDO PLACE",
"SOMERSET GARDENS BY CHELSEA": "VECS ALF SOMERSET GARDENS SENIOR LIVING",
"ARBORS AT WESTBURY ASSISTED LIVING": "VECS ALF THE ARBORS AT WESTBURY",
"THE KENSINGTON WHITE PLAINS": "VECS ALF THE KENSINGTON WHITE PLAINS",
"THE BRISTAL ASSISTED LIVING AT JERICHO": "VECS ALF BRISTAL ASSISTED LIVING AT JERICHO",
"THE BRISTAL AT EAST MEADOW": "VECS ALF BRISTAL ASSISTED LIVING AT EAST MEADOW",
"THE BRISTAL AT LAKE GROVE ALF": "VECS ALF BRISTAL ASSISTED LIVING AT LAKE GROVE",
"THE BRISTAL AT NORTH HILLS": "VECS ALF BRISTAL ASSISTED LIVING AT NORTH HILLS",
"THE BRISTAL AT SAYVILLE": "VECS ALF BRISTAL ASSISTED LIVING AT SAYVILLE",
"THE BRISTAL AT YORK AVENUE ALF": "VECS ALF BRISTAL ASSISTED LIVING AT YORK AVENUE",
"AMSTERDAM AT HARBORSIDE": "VECS AMSTERDAM AT HARBORSIDE (AMSTERDAM HOUSE CONTINUING CARE RETIREMENT COMMUNITY)",
"GOOD SAMARITAN HOSPITAL MEDICAL CENTER": "VECS GOOD SAMARITAN HOSPITAL MEDICAL CENTER NURSING HOME",
"GURWIN JEWISH NURSING & REHAB CENTER": "VECS GURWIN JEWISH NURSING & REHAB CENTER",
"THE ARBORS AT ISLANDIA EAST ALF": "VECS ALF THE ARBORS AT ISLANDIA EAST",
"VALLEY VIEW CENTER FOR NURSING CARE AND REHABILITATION": "VECS THE VALLEY VIEW CENTER FOR NURSING CARE AND REHABILITATION",
"VILLA CREST NURSING & RETIREMENT CENTER": "VILLA CREST NURSING AND RETIREMENT CENTER",
"NYS VETERANS HOME AT BATAVIA": "VETERANS HOME AT BATAVIA",
"UNIVERSITY CENTER FOR NURSING AND HEALING": "VIVO HEALTHCARE UNIVERSITY",
"RFALL RIVER JEWISH HOME": "FALL RIVER JEWISH HOME",
"GENEVA LIVING CENTER NORTH": "LIVING CENTERS AT GENEVA NORTH",
"AUTUMN VIEW": "MCGUIRE GROUP - AUTUMN VIEW HEALTH CARE FACILITY",
"AUTUMN VIEW HEALTH CARE FACILITY": "MCGUIRE GROUP - AUTUMN VIEW HEALTH CARE FACILITY",
"RIVERS EDGE REHAB AND HEALTHCARE CENTER": "RIVER'S EDGE REHABILITATION AND HEALTHCARE CENTER",
"ROSCOE COMMUNITY NURSING HOME CO INC": "ROSCOE NURSING AND REHABILITATION CENTER",
"LEGACY AT BOCA RATON REHABILITATION & NURSING CENTER": "THE LEGACY AT BOCA RATON REHABILITATION AND NURSING CENTER",
"MEADOWS CENTER": "THE MEADOWS CENTER FOR NURSING AND HEALING",
"ATRIA NEW CITY": "VECS ALF ATRIA NEW CITY",
"SALAMANCA REHAB AND NURSING CENTER": "ABSOLUT - SALAMANCA REHABILITATION AND NURSING CENTER",
    "ALAMEDA CENTER FOR REHABILITATION AND HEALTHCARE": "ALAMEDA CENTER FOR REHABILITATION AND HEALTHCARE",
    "ALPINE REHAB AND NURSING CENTER": "ALPINE REHABILITATION & NURSING CENTER",
    "ALPINE REHAB & NURSING CENTER": "ALPINE REHABILITATION & NURSING CENTER",
    'AVANT REHABILITATION & CARE CENTER': "AVANT REHABILITATION & CARE CENTER",
    "BAY POINTE REHAB AND NURSING": "BAY POINTE REHABILITATION AND NURSING",
    "BRANDON CENTER FOR NURSING & REHABILITATION": "BRANDON CENTER FOR NURSING & REHABILITATION",
    "BUSHWICK CENTER FOR REHAB AND HEALTHCARE": "BUSHWICK CENTER FOR REHABILITATION AND HEALTHCARE",
    "CAYUGA NURSING AND REHABILITATION CENTER": "CAYUGA NURSING AND REHABILITATION CENTER",
    "ELIOT CENTER FOR HEALTH & REHABILITATION": "ELIOT CENTER FOR HEALTH AND REHABILITATION",
    "GOWANDA REHAB AND NURSING CENTER": "GOWANDA REHABILITATION AND NURSING CENTER",
    "KING DAVID CENTER FOR NURSING & REHABILITATION": "KING DAVID CENTER FOR NURSING & REHABILITATION",
    "HORNELL GARDENS": "MAPLE LEAF HEALTHCARE CENTER",
    "MAPLE CITY REHABILITATION AND NURSING CENTER": "MAPLE LEAF HEALTHCARE CENTER",
    "MAPLEWOOD REHAB AND NURSING CENTER": "MAPLEWOOD REHABILITATION AND NURSING CENTER",
    "MASSENA REHAB & NURSING CENTER": "MASSENA REHABILITATION AND NURSING CENTER",
    "MATTISON CROSSING ASSISTED LIVING": "MATTISON CROSSING AT MANALAPAN AVE",
    "GARDEN GATE HEALTH CARE FACILITY": "MCGUIRE GROUP - GARDEN GATE HEALTH CARE FACILITY",
    "ST. LUKE RESIDENTIAL HEALTH CARE FACILITY, INC.": "MVHS REHABILITATION & NURSING CENTER (ST. LUKES HOME)",
    "NANS POINTE REHAB AND NURSING": "NANS POINTE REHABILITATION AND NURSING",
    "ORCHARD REHAB AND NURSING CENTER": "ORCHARD REHABILITATION AND NURSING CENTER",
    "ROCHESTER COMMUNITY NURSING AND REHAB": "ROCHESTER COMMUNITY NURSING AND REHAB CENTER",
    "SAUGUS REHAB AND NURSING CENTER": "SAUGUS REHABILITATION AND NURSING CENTER",
    "SAUNDERS NURSING & REHABILITATION CENTER": "SAUNDERS NURSING AND REHABILITATION CENTER",
    "SUNRISE MANOR CENTER FOR NURSING & REHABILITATION": "SUNRISE MANOR CENTER FOR NURSING AND REHABILITATION",
    "SUNSET NURSING AND REHABILITATION CENTER": "SUNSET NURSING AND REHABILITATION CENTER",
    "THE GROVE CENTER FOR REHAB AND HEALTHCARE": "THE GROVE CENTER FOR REHABILITATION AND HEALTHCARE",
    "THE GROVE CENTER FOR REHAB AND HEALTHCARE": "THE GROVE CENTER FOR REHABILITATION AND HEALTHCARE",
    "THE PINES AT PHILADELPHIA REHAB AND HEALTHCARE": "THE PINES AT PHILADELPHIA REHABILITATION AND HEALTHCARE CENTER",
    "PA THE PINES AT PHILDEPHIA REHAB AND HEALTHCARE": "THE PINES AT PHILADELPHIA REHABILITATION AND HEALTHCARE CENTER",
    "TWIN OAKS REHAB AND NURSING CENTER": "TWIN OAKS REHABILITATION AND NURSING CENTER",
    "UTICA REHAB AND NURSING CENTER": "UTICA REHABILITATION AND NURSING CENTER",
    "ACADIA CENTER FOR NURSING AND REHABILITATION": "VECS ACADIA CENTER FOR NURSING AND REHABILITATION",
    "THE ARBORS AT ISLANDIA WEST": "VECS ALF THE ARBORS AT ISLANDIA WEST",
    "THE BRISTAL ASSISTED LIVING AT GARDEN CITY": "VECS ALF BRISTAL ASSISTED LIVING AT GARDEN CITY",
    "BRISTAL ASSISTED LIVING AT EAST NORTHPORT": "VECS ALF BRISTAL ASSISTED LIVING AT EAST NORTHPORT",
    "THE BRISTAL ASSISTED LIVING AT LYNBROOK": "VECS ALF BRISTAL ASSISTED LIVING AT LYNBROOK",
    "DALEVIEW CARE CENTER": "VECS DALEVIEW CARE CENTER",
    "ISLAND REHABILITATION AND NURSING CENTER": "VECS ISLAND REHABILITATION AND NURSING CENTER",
    "ST.CATHERINE OF SIENA NURSING HOME": "VECS ST. CATHERINE OF SIENA NURSING HOME",
    "ST.CATHERINE OF SIENA NURSING HOME": "VECS ST. CATHERINE OF SIENA NURSING HOME",
    "NORMANDY CENTER": "VIVO HEALTHCARE NORMANDY",
    "ORANGE PARK CENTER FOR NURSING AND HEALING": "VIVO HEALTHCARE ORANGE PARK",
    "THE WARTBURG HOME": "WARTBURG SKILLED NURSING FACILITY",
    "WEDGEWOOD REHAB AND NURSING CENTER": "WEDGEWOOD REHAB AND NURSING CENTER",
    "GARDEN GATE": "MCGUIRE GROUP - GARDEN GATE HEALTH CARE FACILITY",
    "AZURE SHORES": "AZURE SHORES REHABILITATION & CARE CENTER",
    "ST. JOHNLAND NURSING CENTER": "ST. JOHNLAND NURSING CENTER",
    "ST JOHNLAND NURSING CENTER": "ST. JOHNLAND NURSING CENTER",
    "ST. JOHNLAND ASSISTED LIVING, INC": "ST. JOHNLAND NURSING CENTER",
    "ST.JOHNLAND NURSING CENTER":"ST. JOHNLAND NURSING CENTER",
    "PROMEDICA SKILLED NURSING AND REHAB": "EASTON SKILLED NURSING & REHAB (PROMEDICA)",
    "DIAMOND NURSING AND REHABILITATION": "COLLAR CITY NURSING AND REHABILITATION CENTER",
    "YORKTOWN REHAB AND NURSING CENTER": "YORKTOWN REHABILITATION AND NURSING CENTER",
    "MVHS REHABILITATION AND NURSING CENTER": "MVHS REHABILITATION & NURSING CENTER (ST. LUKES HOME)",
    "THE BRISTAL AT LAKE SUCCESS": "VECS ALF BRISTAL ASSISTED LIVING AT LAKE SUCCESS",
    "MAPLE REST ALF": "VECS ALF MAPLE REST",
    "THE VILLA AT WESTHAMPTON": "VECS ALF THE VILLA AT WESTHAMPTON",
    "WILLOW TOWERS ALF": "WILLOW TOWERS",
    "WILLOW TOWERS ALF": "VECS ALF WILLOW TOWERS",
    "THE ARBORS AT HAUPPAUGE ALF": "VECS ALF THE ARBORS AT HAUPPAUGE",
    "FAIRLAWN ADULT HOME ALF": "VECS ALF FAIRLAWN ADULT HOME",
    "ALF SUNRISE EAST SETAUKET": "VECS ALF SUNRISE EAST SETAUKET",
    "MAPLE POINT ROCKVILLE CENTER": "VECS ALF MAPLE POINTE AT ROCKVILLE CENTRE AL",
    "ROCKVILLE CENTER COVENT HOME": "VECS ALF ROCKVILLE CENTER COVENT HOME",
    "WYOMING COUNTY COMMUNITY HOSPITAL-NURSING FACILITY": "WYOMING COUNTY HOSPITAL SNF",
    "SKY VIEW REHABILITATION HEALTH CARE": "SKY VIEW REHABILITATION AND HEALTH CARE",
    "TWIN LAKES REHAB AND HEALTHCARE CENTER": "TWIN LAKES REHABILITATION AND HEALTHCARE CENTER",
    "AMBASSADOR ADULT MEDICAL DAYCARE": "AMBASSADOR ADULT MEDICAL DAY CARE CENTER",
    "HAMILTON ARMS CENTER OPCO LLC": "HAMILTON ARMS CENTER",
    "SUSQUEHANNA REHABILITATION & WELLNESS CENTER LLC": "SUSQUEHANNA HEALTH AND WELLNESS CENTER",
    "ASPIRE AT FLETCHER":"ASPIRE OF FLETCHER",


    "BRIGHTVIEW SAYVILLE": "VECS ALF BRIGHTVIEW SAYVILLE",
    "ELMORE ADULT HOME ALF": "VECS ALF ELMORE HOME FOR ADULTS",
    "LAKEVIEW HOUSE SKILLED NURSING": "LAKEVIEW HOUSE SKILLED NURSING AND RESIDENTIAL CARE FACILITY",
    "COLONIAL FOXDEN ALF": "COLONIAL FOXDEN",
    "THE PAVILION AT ROBINSON TERRACE ALF": "THE PAVILION AT ROBINSON TERRACE (ALP)",
    "VECS NEW GLEN OAKS NURSING HOME": "NEW GLEN OAKS NURSING HOME",
    "SACHEM ALF": "VECS SACHEM ADULT HOME",
    "BRISTAL ASSISTED LIVING AT HOLTSVILLE": "VECS ALF BRISTAL ASSISTED LIVING AT HOLTSVILLE",
    "WHISPER WOODS OF SMITHTOWN ALF": "VECS ALF WHISPER WOODS OF SMITHTOWN",
    "WATERVIEW HEIGHTS REHAB AND NURSING": "WATERVIEW HEIGHTS REHABILITATION AND NURSING CENTER",
    "AZURE SHORES": "AZURE SHORES REHABILITATION & CARE CENTER",
    "NEW HAVEN MANOR HOME FOR ADULTS": "VECS ALF MANORHAVEN ADULT HOME",
    "SUNRISE EAST 56TH STREET ALF": "VECS ALF SUNRISE EAST 56TH STREET",
    "ALF SUNRISE OF SMITHTOWN": "VECS SUNRISE OF SMITHTOWN",
    "VALLEY VISTA ADULT/ASSISTED": "VECS ALF VALLEY VISTA",
    "ORCHARD BROOKE ALF": "ABSOLUT CARE OF ORCHARD BROOKE"

}
# Create a mapping dictionary Provider of service
name_mapping = {
    "CANDARA, THOMAS LAWRENCE":"CANDARA, THOMAS" ,
    "HOLCOMB, CHRISTOPHER": "HOLCOMB, CHRISTOPHER JUSTIN",
    "CARLSON, REUBEN": "CARLSON, RUBEN",
    "ROACH, POLLYANNA": "ROACH, POLLYANNA POLLY",
    "PARUSZEWSKI, JEFFREY": "CRAIG, JEFFREY PARUSZEWSKI DR.",
    "RUBACKIN-HAYWARD, NICOLE": "HAYWARD, NICOLE",
    "BELL, HEATHER A": "BELL, HEATHER",
    "VALAINDO, SAMANTHA": "VALIANDO, SAMANTHA"

}

# Update the "Provider of Service Name" in the 2023 file based on the mapping
df_2023["Provider of Service Name"] = df_2023["Provider of Service Name"].replace(name_mapping)

# Update the Location of Service Name in the "2023" file based on the location_changes dictionary
df_2023["Location of Service Name"] = df_2023["Location of Service Name"].replace(location_changes)

# Select the required fields from "2023" file
df_2023 = df_2023[["Date of Service", "Provider of Service Name", "Location of Service Name", "Total Payments Amount", "Action Code", "Primary Insurance Carrier Name", "Due total: Patient + Insurance"]]

# Change Total Payments Amount to positive values
df_2023["Total Payments Amount"] = df_2023["Total Payments Amount"].abs()

df_2023_aggregated = df_2023.groupby(["Date of Service", "Provider of Service Name", "Location of Service Name"]).agg({
    "Total Payments Amount": "sum",
    "Due total: Patient + Insurance": "sum",
    "Action Code": lambda x: x.iloc[0],
    "Primary Insurance Carrier Name": lambda x: x.iloc[0]
}).reset_index()


# Select the required fields from "Master" file
df_master = df_master[["Practitioner", "Total Provider Cost", "Visit Compensation", "Facility", "DOS", "Entity", "Specialty","PT Encounter", "Pre #"]]

# Aggregate the fields per "DOS", "Practitioner", "Facility", "Entity", and "Specialty"
# Group by multiple columns and calculate the sums of "Total Provider Cost" and "Visit Compensation"
df_master_aggregated = df_master.groupby(["DOS", "Practitioner", "Facility", "Entity", "Specialty", "PT Encounter", "Pre #"]).agg({
    "Total Provider Cost": "sum",
    "Visit Compensation": "sum"
}).reset_index()

# Calculate the total "Visit Compensation" for the entire dataset
total_visit_compensation = df_master_aggregated["Visit Compensation"].sum()

# Sort both DataFrames by "DOS"/"Date of Service" column
df_master_aggregated = df_master_aggregated.sort_values("DOS")
df_2023_aggregated = df_2023_aggregated.sort_values("Date of Service")

# Convert date columns to datetime format
df_master_aggregated["DOS"] = pd.to_datetime(df_master_aggregated["DOS"])
df_2023_aggregated["Date of Service"] = pd.to_datetime(df_2023_aggregated["Date of Service"])

# Define columns
master_columns = ["DOS", "Practitioner", "Facility", "Entity", "Specialty", "PT Encounter", "Pre #", "Total Provider Cost", "Visit Compensation"]
df2023_columns = ["Date of Service", "Provider of Service Name", "Location of Service Name", "Total Payments Amount", "Due total: Patient + Insurance", "Action Code", "Primary Insurance Carrier Name"]

# PRIMARY MERGE
df_merged = pd.merge(
    df_master_aggregated,
    df_2023_aggregated,
    left_on=["DOS", "Practitioner", "Facility"],
    right_on=["Date of Service", "Provider of Service Name", "Location of Service Name"],
    how="outer",
    indicator=True
)

# Separate matched and unmatched records from the primary merge
matched_from_primary = df_merged[df_merged["_merge"] == "both"]
unmatched_from_primary = df_merged[df_merged["_merge"] != "both"]

# Extract unmatched rows for secondary merge
df_unmatched_master = unmatched_from_primary[master_columns].dropna(subset=["DOS", "Practitioner", "Facility"]).copy()
df_unmatched_2023 = unmatched_from_primary[df2023_columns].dropna(subset=["Date of Service", "Provider of Service Name", "Location of Service Name"]).copy()

# Aggregation for unmatched master and 2023 data
df_unmatched_master_agg = df_unmatched_master.groupby(["DOS", "Practitioner", "Facility", "Entity", "Specialty", "PT Encounter", "Pre #"]).agg({
    "Total Provider Cost": "sum",
    "Visit Compensation": "sum"
}).reset_index()

df_unmatched_2023_agg = df_unmatched_2023.groupby(["Date of Service", "Provider of Service Name", "Location of Service Name"]).agg({
    "Total Payments Amount": "sum",
    "Due total: Patient + Insurance": "sum",
    "Action Code": "first",
    "Primary Insurance Carrier Name": "first"
}).reset_index()

# SECONDARY MERGE using aggregated unmatched datasets
df_secondary_merge = pd.merge(
    df_unmatched_master_agg,
    df_unmatched_2023_agg,
    left_on=["Practitioner", "Facility"],
    right_on=["Provider of Service Name", "Location of Service Name"],
    how="outer",
    indicator="secondary_merge_indicator"
)

# Separate matched and unmatched from secondary merge
matched_from_secondary = df_secondary_merge[df_secondary_merge["secondary_merge_indicator"] == "both"]

# Only considering unmatched rows from secondary merge for the unmatched.csv
unmatched_after_secondary = df_secondary_merge[df_secondary_merge["secondary_merge_indicator"] != "both"]

# Concatenate matched rows from both merges
all_matched = pd.concat([matched_from_primary, matched_from_secondary], axis=0, ignore_index=True)[master_columns + df2023_columns]

# Directory paths for output
output_directory = r"C:\Users\serge\Desktop\DOV"
matched_file_path = os.path.join(output_directory, "matched.csv")
unmatched_file_path = os.path.join(output_directory, "unmatched.csv")

# Save the DataFrames
all_matched.to_csv(matched_file_path, index=False)
unmatched_after_secondary.to_csv(unmatched_file_path, index=False)

# Print the counts
print("Total items in matched file:", len(all_matched))
print("Total items in unmatched file:", len(unmatched_after_secondary))
# Read the CSV file into a DataFrame
file_path = r'C:\Users\serge\Desktop\DOV\matched.csv'
df = pd.read_csv(file_path)

# Calculate the subtracted values and assign them to a new column
df['Profitability'] = df['Total Payments Amount'] - df['Total Provider Cost']

# Calculate the new metrics
df['Profitability/PT Encounter'] = df['Profitability'] / df['PT Encounter']
df['Total Provider Cost/PT Encounter'] = df['Total Provider Cost'] / df['PT Encounter']

# Save the updated DataFrame back to the CSV file
df.to_csv(file_path, index=False)

# Print the updated DataFrame
print(df)


import pandas as pd
from pathlib import Path
import sqlite3
import pickle
import numpy as np

# Function to print debug information
def debug_print(message, df=None):
    print(message)
    if df is not None:
        print(df.head())
    print("\n")

# Set the path for the CSV file
file_path = Path('C:\\Users\\serge\\Desktop\\DOV\\2023\\HHA_Dov_2023.csv')

# Define the path for the output CSV file
output_path = Path('C:\\Users\\serge\\Desktop\\DOV\\Dov Revenue Project\\Payments_Adj.csv')

# Read the CSV file into a DataFrame
df = pd.read_csv(file_path, parse_dates=['Date of Service'], low_memory=False)
debug_print("Initial DataFrame loaded:", df)
print("Total Payments Sum after initial load:", df['Total Payments Amount'].sum())

# Rename the columns for ease of use
rename_columns = {
    "Transaction Code (Charge, Payment or Adjustment)": "Transaction_Code",
    "Provider of Service Name": "Provider_of_Service_Name",
    "Location of Service Name": "Location_of_Service_Name",
    "Primary Insurance Carrier Name": "Primary_Insurance_Carrier_Name",
    "Total Payments Amount": "Total_Payments_Amount",
    "Total Adjustments Amount": "Total_Adjustments_Amount",
    "Transaction Amount": "Transaction_Amount"

}
df.rename(columns=rename_columns, inplace=True)
debug_print("Columns renamed:", df)
print("Columns after renaming:", df.columns)


# Ensure 'Units of Service' is numeric
df['Units of Service'] = pd.to_numeric(df['Units of Service'], errors='coerce').fillna(0)
debug_print("Units of Service converted to numeric:", df)
print("Total Payments Sum after renaming and initial cleaning:", df['Total_Payments_Amount'].sum())


# Identify and remove voided transactions
indices_to_remove = set()
negative_units_transactions = df[(df['Units of Service'] < 0) & (df['Total_Payments_Amount'] == 0)]

for index, row in negative_units_transactions.iterrows():
    matching_positives = df[
        (df['Date of Service'] == row['Date of Service']) &
        (df['Transaction_Code'] == row['Transaction_Code']) &
        (df['TRANSACTION AMOUNT'] == -row['TRANSACTION AMOUNT']) &
        (df['Units of Service'] == -row['Units of Service']) &
        (df['Total_Payments_Amount'] == 0)  # Additional condition for zero payment
    ].index
    
    if not matching_positives.empty:
        indices_to_remove.update([index])
        indices_to_remove.update(matching_positives)

df.drop(list(indices_to_remove), inplace=True)

# Debug prints
print("Voided transactions removed. Remaining transaction count:", df.shape[0])
print("Total Payments Sum after removing voided transactions:", df['Total_Payments_Amount'].sum())
debug_print("Voided transactions removed. DataFrame after removal:", df)
print("Total Payments Sum after removing negative units:", df['Total_Payments_Amount'].sum())
print("Count after removal:", df.shape[0])
print("Transactions being removed (Negative Units):")
print(negative_units_transactions.head())
print("Transactions being removed (Matching Positives):")

# Fill missing values in the grouping columns with 'Unknown'
grouping_columns = ['Date of Service', 'Location_of_Service_Name', 
                    'Primary_Insurance_Carrier_Name', 'Provider_of_Service_Name', 
                    'Transaction_Code']

for col in grouping_columns:
    df[col] = df[col].fillna('Unknown')

# Group by the specified columns and aggregate the sums
grouped_df = df.groupby(grouping_columns).agg({
    'Total_Payments_Amount': 'sum'
}).reset_index()

# Rename the columns to reflect the aggregated sums
grouped_df.rename(columns={
    'Total_Payments_Amount': 'Total_Payments_Amount_Sum',
    'Total_Adjustments_Amount': 'Total_Adjustments_Amount_Sum'
}, inplace=True)

# Multiply 'Total_Payments_Amount_Sum' by -1
grouped_df['Total_Payments_Amount_Sum'] *= -1
print("Total Payments Sum after grouping and aggregating:", grouped_df['Total_Payments_Amount_Sum'].sum())

# Save the grouped DataFrame using Pickle
grouped_df.to_pickle('C:\\Users\\serge\\Desktop\\DOV\\Dov Revenue Project\\grouped_df.pkl')

# Print the resulting DataFrame with total sums
debug_print("Total sums of payments and adjustments per specified columns:", grouped_df)

# Save the result to a CSV file
grouped_df.to_csv(output_path, index=False)
print(f"CSV file with total sums has been saved to: {output_path}")
print("Total Payments Sum after grouping and aggregating:", grouped_df['Total_Payments_Amount_Sum'].sum())


# Ensure 'Units of Service' is numeric
df['Units of Service'] = pd.to_numeric(df['Units of Service'], errors='coerce').fillna(0)

# Convert Total Payments Amount to positive values
df['Total_Payments_Amount'] = df['Total_Payments_Amount'] * -1

# New prices effective from October 1, 2023
new_prices = {'Q4253': 333.68, 'Q4248': 822.73}
price_change_date = pd.to_datetime('2023-10-01')

# Special handling for transaction codes 'Q4253' and 'Q4248'
# Original prices before October 1, 2023
special_codes = {'Q4253': 482.00, 'Q4248': 868.44}

# Initialize a column for Estimated_Revenue in the original DataFrame
df['Estimated_Revenue'] = 0.0

# Function to determine the correct price based on the date of service
def get_price(code, date_of_service):
    if date_of_service >= price_change_date:
        return new_prices[code]
    else:
        return special_codes[code]

# Iterate over each special code to calculate Estimated_Revenue
for code in special_codes.keys():
    # Identify the rows for the specific Q code
    condition = df['Transaction_Code'] == code
    
    # Apply the price based on the date of service
    df.loc[condition, 'Price_Per_Unit'] = df.loc[condition, 'Date of Service'].apply(lambda date: get_price(code, date))

    # Calculate the expected payment if all units were paid
    df.loc[condition, 'Expected_Payment'] = df.loc[condition, 'Units of Service'] * df.loc[condition, 'Price_Per_Unit']
    
    # Calculate the revenue that is still expected (owed) due to underpayment
    df.loc[condition, 'Revenue_Owed'] = df.loc[condition, 'Expected_Payment'] - df.loc[condition, 'Total_Payments_Amount']

    # Calculate the Estimated_Revenue for rows with zero payment amount
    zero_payment_condition = condition & (df['Total_Payments_Amount'] == 0)
    df.loc[zero_payment_condition, 'Estimated_Revenue'] = df.loc[zero_payment_condition, 'Units of Service'] * df.loc[zero_payment_condition, 'Price_Per_Unit']

    # Add the owed revenue to the Estimated_Revenue for underpaid units
    condition_owed = condition & (df['Revenue_Owed'] > 0)
    df.loc[condition_owed, 'Estimated_Revenue'] += df.loc[condition_owed, 'Revenue_Owed']

# Remove the temporary columns used for calculations
columns_to_drop = ['Expected_Payment', 'Revenue_Owed', 'Price_Per_Unit']
df.drop(columns=columns_to_drop, inplace=True, errors='ignore')
print("Total Payments Sum after handling special codes:", df['Total_Payments_Amount'].sum())
print("Total Estimated Revenue for Special Codes:", df['Estimated_Revenue'].sum())

# Create a separate q_codes_summary DataFrame
q_codes_summary = df[df['Transaction_Code'].isin(special_codes.keys())].groupby([
    'Date of Service', 'Location_of_Service_Name', 'Primary_Insurance_Carrier_Name',
    'Provider_of_Service_Name', 'Transaction_Code'
]).agg({
    'Estimated_Revenue': 'sum'
}).reset_index()

# Group by the specified columns and aggregate the sums for all codes
grouped_df = df.groupby([
    'Date of Service',
    'Location_of_Service_Name',
    'Primary_Insurance_Carrier_Name',
    'Provider_of_Service_Name',
    'Transaction_Code'
]).agg({
    'Total_Payments_Amount': 'sum',
    'Total_Adjustments_Amount': 'sum',
    'Estimated_Revenue': 'sum'  # Include Estimated_Revenue in aggregation
}).reset_index()

# Rename the columns to reflect the aggregated sums
grouped_df.rename(columns={
    'Total_Payments_Amount': 'Total_Payments_Amount_Sum',
    'Total_Adjustments_Amount': 'Total_Adjustments_Amount_Sum'
}, inplace=True)

# Multiply 'Total_Payments_Amount_Sum' by -1
grouped_df['Total_Payments_Amount_Sum'] *= -1

# Save the grouped DataFrame to a CSV file
grouped_df.to_csv(output_path, index=False)
print(f"CSV file with total sums and estimated revenue has been saved to: {output_path}")
print("Total Payments Sum after handling special codes:", df['Total_Payments_Amount'].sum())
print("Total Estimated Revenue in q_codes_summary:", q_codes_summary['Estimated_Revenue'].sum())

# Print columns in q_codes_summary
print("Columns in q_codes_summary:")
print(q_codes_summary.columns)
# Print the structure of q_codes_summary
print("Structure of q_codes_summary:")
print(q_codes_summary.dtypes)  # This will print the data type of each column

# Print the first few rows to inspect the DataFrame
print("\nFirst few rows of q_codes_summary:")
print(q_codes_summary.head())

# Merge the Q codes summary with grouped_df
grouped_df = grouped_df.merge(q_codes_summary, 
                              on=['Date of Service', 'Location_of_Service_Name', 
                                  'Primary_Insurance_Carrier_Name', 'Provider_of_Service_Name', 
                                  'Transaction_Code'], 
                              how='left')



# Convert to absolute values and fill NaNs where needed
df['Total_Payments_Amount'] = df['Total_Payments_Amount'].fillna(0).abs()
df['Total_Adjustments_Amount'] = df['Total_Adjustments_Amount'].fillna(0).abs()

# Create Day Name column with the actual date
df['Day_Name'] = df['Date of Service'].dt.strftime('%Y-%m-%d')

# Convert all necessary fields to string type
str_columns = ['Transaction_Code', 'Provider_of_Service_Name', 'Location_of_Service_Name', 'Primary_Insurance_Carrier_Name']
for col in str_columns:
    df[col] = df[col].astype(str)
debug_print("Columns converted to string and Day_Name added:", df)

final_results_path = 'C:\\Users\\serge\\Desktop\\DOV\\Dov Revenue Project\\final_results_with_estimated_revenue.csv'


# Calculate the overall average payment per transaction code, location, and insurance company
average_payments = df[df['Total_Payments_Amount'] > 0].groupby(
    ['Transaction_Code', 'Location_of_Service_Name', 'Primary_Insurance_Carrier_Name']
).agg({'Total_Payments_Amount': 'mean'}).rename(columns={'Total_Payments_Amount': 'Average_Payment'})

# If any of the variables are missing for this calculation to take place,
# use a different set of variables limited only to average payment per transaction code.
average_payments_fallback = df[df['Total_Payments_Amount'] > 0].groupby(
    'Transaction_Code'
)['Total_Payments_Amount'].mean().reset_index(name='Average_Payment_Fallback')

# Merge the average payments with the original DataFrame
merged_data = df.merge(average_payments, how='left', 
                       on=['Transaction_Code', 'Location_of_Service_Name', 'Primary_Insurance_Carrier_Name'])

# Where Average_Payment is NaN, fill in with the fallback average payment
merged_data = merged_data.merge(average_payments_fallback, how='left', on='Transaction_Code')
merged_data['Average_Payment'] = merged_data['Average_Payment'].fillna(merged_data['Average_Payment_Fallback'])

# Clean up the columns - no longer needed fallback column
merged_data.drop(columns=['Average_Payment_Fallback'], inplace=True)

# Count the number of zero payments per transaction code, location, insurance company per date of service
zero_payment_counts = df[df['Total_Payments_Amount'] == 0].groupby(
    ['Date of Service', 'Transaction_Code', 'Location_of_Service_Name', 'Primary_Insurance_Carrier_Name']
).size().reset_index(name='Zero_Payment_Count')

# Merge the zero payment counts with the average payments
final_results = merged_data.merge(zero_payment_counts, how='left', 
                                  on=['Date of Service', 'Transaction_Code', 'Location_of_Service_Name', 'Primary_Insurance_Carrier_Name'])

# Fill NaN values in Zero_Payment_Count with 0
final_results['Zero_Payment_Count'] = final_results['Zero_Payment_Count'].fillna(0)

# Update 'Estimated_Revenue_NonQ' where 'Transaction_Code' starts with 'Q'
condition = final_results['Transaction_Code'].str.startswith('Q')
final_results.loc[condition, 'Estimated_Revenue_NonQ'] = final_results.loc[condition, 'Estimated_Revenue']

# Assume the 'final_results_path' variable is defined earlier in your script and points to your desired CSV output path.
final_results.to_csv(final_results_path, index=False)


# Define the path for the output CSV file
final_results_path = 'C:\\Users\\serge\\Desktop\\DOV\\Dov Revenue Project\\final_results_with_estimated_revenue.csv'

# Check for missing Average_Payment after merging
missing_avg_payment = final_results['Average_Payment'].isna()
debug_print("Rows with missing Average_Payment after merging:", final_results[missing_avg_payment])


# Check for missing Average_Payment after merging
missing_avg_payment = final_results['Average_Payment'].isna()
debug_print("Rows with missing Average_Payment after merging:", final_results[missing_avg_payment])

# Output the non-Q code estimated revenue data for review
print("Non-Q Code Estimated Revenue Data:")
print(merged_data.head())

# Define the path for the output CSV file for non-Q code estimated revenue
output_csv_path_non_q = 'C:\\Users\\serge\\Desktop\\DOV\\Dov Revenue Project\\non_q_estimated_revenue.csv'

# Save the non-Q code estimated revenue data to a CSV file
merged_data.to_csv(output_csv_path_non_q, index=False)
print(f"CSV file with non-Q code estimated revenue has been saved to: {output_csv_path_non_q}")

# Output the final DataFrame
print(merged_data.head())

# Save the final DataFrame to a CSV file
merged_data.to_csv('C:\\Users\\serge\\Desktop\\DOV\\Dov Revenue Project\\new_approach_est.csv', index=False)
print("CSV file with estimated revenue for non-Q code transactions has been saved.")

# Output the final merged data
print(final_results.head())

print("Final Total Payments Sum:", final_results['Total_Payments_Amount'].sum())
# Check if 'Estimated_Revenue' exists in final_results before merging
if 'Estimated_Revenue' in final_results.columns:
    print("Estimated_Revenue column exists in final_results.")
else:
    print("Estimated_Revenue column does not exist in final_results. Please check your calculations.")

# Merge the Q codes summary with final_results
final_results = final_results.merge(
    q_codes_summary, 
    on=['Date of Service', 'Location_of_Service_Name', 'Primary_Insurance_Carrier_Name', 
        'Provider_of_Service_Name', 'Transaction_Code'], 
    how='left'
)

# Calculate 'Estimated_Revenue_NonQ' for each row
final_results['Estimated_Revenue_NonQ'] = final_results['Zero_Payment_Count'] * final_results['Average_Payment']

# Identify duplicates in the specified combination of variables, excluding 'Estimated_Revenue_NonQ'
duplicate_mask = final_results.duplicated(subset=['Date of Service', 'Transaction_Code', 
                                                  'Location_of_Service_Name', 'Primary_Insurance_Carrier_Name'], 
                                          keep='first')

# Replace only the 'Estimated_Revenue_NonQ' of duplicates with NaN
final_results.loc[duplicate_mask, 'Estimated_Revenue_NonQ'] = np.nan

# Calculate the total of 'Estimated_Revenue_NonQ' after handling duplicates
total_estimated_revenue_nonq = final_results['Estimated_Revenue_NonQ'].sum()
print("Total Estimated Revenue (Non-Q):", total_estimated_revenue_nonq)

# Output a preview of the final DataFrame
print(final_results.head())

# Save the final DataFrame to a CSV file
final_output_csv_path = 'C:\\Users\\serge\\Desktop\\DOV\\Dov Revenue Project\\final_results_with_estimated_revenue.csv'
final_results.to_csv(final_output_csv_path, index=False)
print(f"CSV file with final results including estimated revenue (duplicates handled) has been saved to: {final_output_csv_path}")

# Assuming 'final_results_path' is the path to your CSV file and is defined earlier in your script
final_results_path = 'C:\\Users\\serge\\Desktop\\DOV\\Dov Revenue Project\\final_results_with_estimated_revenue.csv'

# Load the final results to make sure we have the most up-to-date data
final_results = pd.read_csv(final_results_path)

# Verify that 'Estimated_Revenue_y' exists in the DataFrame
if 'Estimated_Revenue_y' not in final_results.columns:
    print("Column 'Estimated_Revenue_y' does not exist in the DataFrame. Please check the CSV file or prior steps in the script.")
else:
    # Update 'Estimated_Revenue_NonQ' where 'Transaction_Code' starts with 'Q'
    condition = final_results['Transaction_Code'].str.startswith('Q')
    final_results.loc[condition, 'Estimated_Revenue_NonQ'] = final_results.loc[condition, 'Estimated_Revenue_y']

    # Save the updated final results
    final_results.to_csv(final_results_path, index=False)
    print(f"CSV file with updated estimated revenue has been saved to: {final_results_path}")

# Load the final results to make sure we have the most up-to-date data
final_results_path = 'C:\\Users\\serge\\Desktop\\DOV\\Dov Revenue Project\\final_results_with_estimated_revenue.csv'
final_results = pd.read_csv(final_results_path)

# Select only the specified fields
final_columns = [
    'Date of Service',
    'Date of Batch',
    'Transaction_Code',
    'Modifier Codes',
    'Units of Service',
    'TRANSACTION AMOUNT',
    'Provider_of_Service_Name',
    'Location_of_Service_Name',
    'Primary_Insurance_Carrier_Name',
    'Action Code',
    'Primary Insurance Deductible',
    'Primary Insurance Coinsurance',
    'Action Code Description',
    'Practice Code',
    'Practice Name',
    'Due total: Patient + Insurance',
    'Total_Payments_Amount',
    'Total_Adjustments_Amount',
    'Average_Payment',
    'Zero_Payment_Count',
    'Estimated_Revenue_NonQ'  # This will be renamed in the next step
]

# Filter the DataFrame to include only the specified columns
final_results = final_results[final_columns]

# Rename the 'Estimated_Revenue_NonQ' column to 'Net_AR_Revenue'
final_results.rename(columns={'Estimated_Revenue_NonQ': 'Net_AR_Revenue'}, inplace=True)

# Save the final DataFrame to a CSV file
final_output_csv_path = 'C:\\Users\\serge\\Desktop\\DOV\\Dov Revenue Project\\final_results_with_estimated_revenue.csv'
final_results.to_csv(final_output_csv_path, index=False)
print(f"CSV file with final results including Net AR Revenue has been saved to: {final_output_csv_path}")
